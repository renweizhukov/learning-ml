{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6. Test Coverage and Parameterized Tests\n",
    "\n",
    "## 6.1 Module outline\n",
    "\n",
    "(1) Parameterized tests with `unittest` and `pytest`\n",
    "\n",
    "(2) Measuring coverage of tests\n",
    "\n",
    "(3) Using code coverage metrics when adding test cases\n",
    "\n",
    "## 6.2 Using a custom `assert` to reduce duplication\n",
    "\n",
    "### 6.2.1 Parameterized tests\n",
    "\n",
    "(1) Same function or method\n",
    "\n",
    "(2) Different parameters\n",
    "\n",
    "### 6.2.2 Example: Tennis scores\n",
    "\n",
    "(1) Love-All\n",
    "\n",
    "(2) Fifteen-Love\n",
    "\n",
    "(3) Fifteen-thirty\n",
    "\n",
    "(4) Fifteen-Forty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE AS tennis.py\n",
    "\n",
    "score_names = [\"Love\", \"Fifteen\", \"Thirty\", \"Forty\"]\n",
    "\n",
    "def tennis_score(player1_points, player2_points):\n",
    "    if player1_points == player2_points:\n",
    "        return \"{0}-All\".format(score_names[player1_points])\n",
    "    else:\n",
    "        return \"{0}-{1}\".format(score_names[player1_points],\n",
    "                                    score_names[player2_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE AS test_tennis.py\n",
    "\n",
    "import unittest\n",
    "\n",
    "from tennis import tennis_score\n",
    "\n",
    "class TennisTest(unittest.TestCase):\n",
    "    \n",
    "    def test_even_scores_early_game(self):\n",
    "        self.assert_tennis_score(\"Love-All\", 0, 0)\n",
    "        self.assert_tennis_score(\"Fifteen-All\", 1, 1)\n",
    "        self.assert_tennis_score(\"Thirty-All\", 2, 2)\n",
    "        \n",
    "    def test_early_games_with_uneven_scores(self):\n",
    "        self.assert_tennis_score(\"Love-Fifteen\", 0, 1)\n",
    "        self.assert_tennis_score(\"Fifteen-Love\", 1, 0)\n",
    "        self.assert_tennis_score(\"Love-Thirty\", 0, 2)\n",
    "        self.assert_tennis_score(\"Thirty-Love\", 2, 0)\n",
    "        \n",
    "    def assert_tennis_score(self, expected_score, player1_points, player2_points):\n",
    "        self.assertEqual(expected_score, tennis_score(player1_points, player2_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ python -m unittest -v\n",
    "test_check_with_too_high_pressure (test_alarm.AlarmTest) ... ok\n",
    "test_check_with_too_low_pressure (test_alarm.AlarmTest) ... ok\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 2 tests in 0.001s\n",
    "\n",
    "OK\n",
    "```\n",
    "\n",
    "## 6.3 Defining parameterized tests with `unittest`\n",
    "\n",
    "Use a metaprogramming technique `setattr` to dynamically generate test routines `test_xxx()` from some test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE AS tennis.py\n",
    "\n",
    "score_names = [\"Love\", \"Fifteen\", \"Thirty\", \"Forty\"]\n",
    "\n",
    "def tennis_score(player1_points, player2_points):\n",
    "    max_points = max(player1_points, player2_points)\n",
    "    min_points = min(player1_points, player2_points)\n",
    "    leading_player = 1 if max_points == player1_points else 2\n",
    "    \n",
    "    if max_points >= 4:\n",
    "        if max_points == min_points:\n",
    "            return \"Deuce\"\n",
    "        elif max_points == min_points + 1:\n",
    "            return \"Advantage Player {}\".format(leading_player)\n",
    "        else:\n",
    "            return \"Win for Player {}\".format(leading_player)\n",
    "    elif max_points == 3 and min_points == 3:\n",
    "        return \"Deuce\"\n",
    "    else:\n",
    "        if player1_points == player2_points:\n",
    "            return \"{0}-All\".format(score_names[player1_points])\n",
    "        else:\n",
    "            return \"{0}-{1}\".format(score_names[player1_points],\n",
    "                                    score_names[player2_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE AS test_tennis.py\n",
    "\n",
    "import unittest\n",
    "\n",
    "from tennis import tennis_score\n",
    "\n",
    "test_case_data = \\\n",
    "{   \"even_scores\" :                     [(\"Love-All\", 0, 0), \n",
    "                                         (\"Fifteen-All\", 1, 1),\n",
    "                                         (\"Thirty-All\", 2, 2),\n",
    "                                        ],\n",
    "    \"early_games_with_uneven_scores\" :  [(\"Love-Fifteen\", 0, 1),\n",
    "                                         (\"Fifteen-Love\", 1, 0),\n",
    "                                         (\"Thirty-Fifteen\", 2, 1),\n",
    "                                         (\"Forty-Thirty\", 3, 2),\n",
    "                                        ],\n",
    "    \"endgame_with_uneven_scores\":       [(\"Advantage Player 1\", 4, 3),\n",
    "                                         (\"Advantage Player 2\", 5, 6),\n",
    "                                         (\"Advantage Player 1\", 13, 12), \n",
    "                                        ],\n",
    "    \"endgame_with_even_scores\":         [(\"Deuce\", 3, 3),\n",
    "                                         (\"Deuce\", 4, 4),\n",
    "                                         (\"Deuce\", 14, 14),  \n",
    "                                        ],\n",
    "    \"there_is_a_winner\":                [(\"Win for Player 1\", 4, 0),\n",
    "                                         (\"Win for Player 2\", 2, 4),\n",
    "                                         (\"Win for Player 1\", 6, 4),\n",
    "                                        ],\n",
    "\n",
    "}\n",
    "\n",
    "def tennis_test_template(*args):\n",
    "    def foo(self):\n",
    "        self.assert_tennis_score(*args)\n",
    "    return foo\n",
    "\n",
    "class TennisTest(unittest.TestCase):\n",
    "\n",
    "    def assert_tennis_score(self, expected_score, player1_points, player2_points):\n",
    "        self.assertEqual(expected_score, tennis_score(player1_points, player2_points))\n",
    "\n",
    "\n",
    "for behaviour, test_cases in test_case_data.items():\n",
    "    for tennis_test_case_data in test_cases:\n",
    "        expected_output, player1_score, player2_score = tennis_test_case_data\n",
    "        test_name = \"test_{0}_{1}_{2}\".format(behaviour, player1_score, player2_score)\n",
    "        tennis_test_case = tennis_test_template(*tennis_test_case_data)\n",
    "        setattr(TennisTest, test_name, tennis_test_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ python -m unittest -v\n",
    "test_early_games_with_uneven_scores_0_1 (test_tennis.TennisTest) ... ok\n",
    "test_early_games_with_uneven_scores_1_0 (test_tennis.TennisTest) ... ok\n",
    "test_early_games_with_uneven_scores_2_1 (test_tennis.TennisTest) ... ok\n",
    "test_early_games_with_uneven_scores_3_2 (test_tennis.TennisTest) ... ok\n",
    "test_endgame_with_even_scores_14_14 (test_tennis.TennisTest) ... ok\n",
    "test_endgame_with_even_scores_3_3 (test_tennis.TennisTest) ... ok\n",
    "test_endgame_with_even_scores_4_4 (test_tennis.TennisTest) ... ok\n",
    "test_endgame_with_uneven_scores_13_12 (test_tennis.TennisTest) ... ok\n",
    "test_endgame_with_uneven_scores_4_3 (test_tennis.TennisTest) ... ok\n",
    "test_endgame_with_uneven_scores_5_6 (test_tennis.TennisTest) ... ok\n",
    "test_even_scores_0_0 (test_tennis.TennisTest) ... ok\n",
    "test_even_scores_1_1 (test_tennis.TennisTest) ... ok\n",
    "test_even_scores_2_2 (test_tennis.TennisTest) ... ok\n",
    "test_there_is_a_winner_2_4 (test_tennis.TennisTest) ... ok\n",
    "test_there_is_a_winner_4_0 (test_tennis.TennisTest) ... ok\n",
    "test_there_is_a_winner_6_4 (test_tennis.TennisTest) ... ok\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "Ran 16 tests in 0.001s\n",
    "\n",
    "OK\n",
    "```\n",
    "\n",
    "## 6.4 Defining parameterized tests with `pytest`\n",
    "\n",
    "Use the decorator `@pytest.mark.parameterize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE AS test_tennis.py\n",
    "\n",
    "from tennis import tennis_score\n",
    "import pytest\n",
    "\n",
    "\n",
    "examples = ((\"expected_score\", \"player1_points\", \"player2_points\", \"comment\"), \n",
    "[\n",
    "(\"Love-All\", 0, 0, \"early game, scores equal\"),\n",
    "(\"Fifteen-All\", 1, 1, \"early game, scores equal\"),\n",
    "(\"Thirty-All\", 2, 2, \"early game, scores equal\"),\n",
    "(\"Love-Fifteen\", 0, 1, \"early game, uneven scores\"),\n",
    "(\"Fifteen-Love\", 1, 0, \"early game, uneven scores\"),\n",
    "(\"Thirty-Fifteen\", 2, 1, \"early game, uneven scores\"),\n",
    "(\"Forty-Thirty\", 3, 2, \"early game, uneven scores\"),\n",
    "(\"Advantage Player 1\", 4, 3, \"endgame, with uneven scores\"),\n",
    "(\"Advantage Player 1\", 23, 22, \"endgame, with uneven scores\"),\n",
    "(\"Deuce\", 3, 3, \"endgame, with even scores\"),\n",
    "(\"Deuce\", 4, 4, \"endgame, with even scores\"),\n",
    "(\"Deuce\", 14, 14, \"endgame, with even scores\"),\n",
    "(\"Win for Player 1\", 4, 0, \"endgame, with winner\"),\n",
    "(\"Win for Player 2\", 1, 4, \"endgame, with winner\"),\n",
    "(\"Win for Player 1\", 6, 4, \"endgame, with winner\"),\n",
    "])\n",
    "@pytest.mark.parametrize(*examples)\n",
    "def test_tennis_scores(expected_score, player1_points, player2_points, comment):\n",
    "    assert expected_score == tennis_score(player1_points, player2_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ python -m pytest -v\n",
    "========================================================= test session starts =========================================================\n",
    "platform linux -- Python 3.6.4, pytest-3.4.2, py-1.5.2, pluggy-0.6.0 -- /home/renwei/anaconda3/envs/ml/bin/python\n",
    "cachedir: .pytest_cache\n",
    "rootdir: /home/renwei/repos/github/learning-ml/python/pluralsight-unit-testing-with-python/parameterized_tennis_pytest, inifile:\n",
    "collected 15 items                                                                                                                    \n",
    "\n",
    "test_tennis.py::test_tennis_scores[Love-All-0-0-early game, scores equal] PASSED                                                [  6%]\n",
    "test_tennis.py::test_tennis_scores[Fifteen-All-1-1-early game, scores equal] PASSED                                             [ 13%]\n",
    "test_tennis.py::test_tennis_scores[Thirty-All-2-2-early game, scores equal] PASSED                                              [ 20%]\n",
    "test_tennis.py::test_tennis_scores[Love-Fifteen-0-1-early game, uneven scores] PASSED                                           [ 26%]\n",
    "test_tennis.py::test_tennis_scores[Fifteen-Love-1-0-early game, uneven scores] PASSED                                           [ 33%]\n",
    "test_tennis.py::test_tennis_scores[Thirty-Fifteen-2-1-early game, uneven scores] PASSED                                         [ 40%]\n",
    "test_tennis.py::test_tennis_scores[Forty-Thirty-3-2-early game, uneven scores] PASSED                                           [ 46%]\n",
    "test_tennis.py::test_tennis_scores[Advantage Player 1-4-3-endgame, with uneven scores] PASSED                                   [ 53%]\n",
    "test_tennis.py::test_tennis_scores[Advantage Player 1-23-22-endgame, with uneven scores] PASSED                                 [ 60%]\n",
    "test_tennis.py::test_tennis_scores[Deuce-3-3-endgame, with even scores] PASSED                                                  [ 66%]\n",
    "test_tennis.py::test_tennis_scores[Deuce-4-4-endgame, with even scores] PASSED                                                  [ 73%]\n",
    "test_tennis.py::test_tennis_scores[Deuce-14-14-endgame, with even scores] PASSED                                                [ 80%]\n",
    "test_tennis.py::test_tennis_scores[Win for Player 1-4-0-endgame, with winner] PASSED                                            [ 86%]\n",
    "test_tennis.py::test_tennis_scores[Win for Player 2-1-4-endgame, with winner] PASSED                                            [ 93%]\n",
    "test_tennis.py::test_tennis_scores[Win for Player 1-6-4-endgame, with winner] PASSED                                            [100%]\n",
    "\n",
    "====================================================== 15 passed in 0.04 seconds ======================================================\n",
    "```\n",
    "\n",
    "## 6.5 Measuring coverage with `pytest-cov`\n",
    "\n",
    "### 6.5.1 Package installation\n",
    "\n",
    "```bash\n",
    "$ pip install coverage pytest-cov\n",
    "```\n",
    "\n",
    "### 6.5.2 Measuring coverage\n",
    "\n",
    "(1) Get a terminal report.\n",
    "\n",
    "```bash\n",
    "$ python -m pytest --cov-report term-missing --cov tennis\n",
    "========================================================= test session starts =========================================================\n",
    "platform linux -- Python 3.6.4, pytest-3.4.2, py-1.5.2, pluggy-0.6.0\n",
    "rootdir: /home/renwei/repos/github/learning-ml/python/pluralsight-unit-testing-with-python/coverage_example_pytest, inifile:\n",
    "plugins: cov-2.5.1\n",
    "collected 15 items                                                                                                                    \n",
    "\n",
    "test_tennis.py ...............                                                                                                  [100%]\n",
    "\n",
    "----------- coverage: platform linux, python 3.6.4-final-0 -----------\n",
    "Name        Stmts   Miss  Cover   Missing\n",
    "-----------------------------------------\n",
    "tennis.py      32      1    97%   29\n",
    "\n",
    "\n",
    "====================================================== 15 passed in 0.06 seconds ======================================================\n",
    "```\n",
    "\n",
    "(2) Get a html report.\n",
    "\n",
    "```bash\n",
    "$ python -m pytest --cov-report html --cov tennis\n",
    "========================================================= test session starts =========================================================\n",
    "platform linux -- Python 3.6.4, pytest-3.4.2, py-1.5.2, pluggy-0.6.0\n",
    "rootdir: /home/renwei/repos/github/learning-ml/python/pluralsight-unit-testing-with-python/coverage_example_pytest, inifile:\n",
    "plugins: cov-2.5.1\n",
    "collected 15 items                                                                                                                    \n",
    "\n",
    "test_tennis.py ...............                                                                                                  [100%]\n",
    "\n",
    "----------- coverage: platform linux, python 3.6.4-final-0 -----------\n",
    "Coverage HTML written to dir htmlcov\n",
    "\n",
    "\n",
    "====================================================== 15 passed in 0.06 seconds ======================================================\n",
    "```\n",
    "\n",
    "(3) Use `#pragma: no cover` to mark the function that should be ignored for coverage analysis.\n",
    "\n",
    "Those lines will be shown as excluded in the html report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE AS tennis.py\n",
    "\n",
    "def tennis_score(p1points, p2points):\n",
    "    game = TennisGame(\"Player 1\", \"Player 2\")\n",
    "    game.p1points = p1points\n",
    "    game.p2points = p2points\n",
    "    return game.score()\n",
    "\n",
    "class TennisGame:\n",
    "\n",
    "    def __init__(self, player1Name, player2Name):\n",
    "        self.player1Name = player1Name\n",
    "        self.player2Name = player2Name\n",
    "        self.p1points = 0\n",
    "        self.p2points = 0\n",
    "    \n",
    "    def score(self):\n",
    "        result = \"\"\n",
    "        tempScore=0\n",
    "        if (self.p1points==self.p2points):\n",
    "            result = {\n",
    "                0 : \"Love-All\",\n",
    "                1 : \"Fifteen-All\",\n",
    "                2 : \"Thirty-All\",\n",
    "            }.get(self.p1points, \"Deuce\")\n",
    "        elif (self.p1points>=4 or self.p2points>=4):\n",
    "            minusResult = self.p1points-self.p2points\n",
    "            if (minusResult==1):\n",
    "                result =\"Advantage \" + self.player1Name\n",
    "            elif (minusResult ==-1):\n",
    "                result =\"Advantage \" + self.player2Name\n",
    "            elif (minusResult>=2):\n",
    "                result = \"Win for \" + self.player1Name\n",
    "            else:\n",
    "                result =\"Win for \" + self.player2Name\n",
    "        else:\n",
    "            for i in range(1,3):\n",
    "                if (i==1):\n",
    "                    tempScore = self.p1points\n",
    "                else:\n",
    "                    result+=\"-\"\n",
    "                    tempScore = self.p2points\n",
    "                result += {\n",
    "                    0 : \"Love\",\n",
    "                    1 : \"Fifteen\",\n",
    "                    2 : \"Thirty\",\n",
    "                    3 : \"Forty\",\n",
    "                }[tempScore]\n",
    "        return result\n",
    "\n",
    "        def won_point(self, playerName): # pragma: no cover\n",
    "            if playerName == self.player1Name:\n",
    "                self.p1points += 1\n",
    "            else:\n",
    "                self.p2points += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE AS test_tennis.py\n",
    "\n",
    "from tennis import tennis_score\n",
    "import pytest\n",
    "\n",
    "\n",
    "examples = ((\"expected_score\", \"player1_points\", \"player2_points\", \"comment\"), \n",
    "[\n",
    "(\"Love-All\", 0, 0, \"early game, scores equal\"),\n",
    "(\"Fifteen-All\", 1, 1, \"early game, scores equal\"),\n",
    "(\"Thirty-All\", 2, 2, \"early game, scores equal\"),\n",
    "(\"Love-Fifteen\", 0, 1, \"early game, uneven scores\"),\n",
    "(\"Fifteen-Love\", 1, 0, \"early game, uneven scores\"),\n",
    "(\"Thirty-Fifteen\", 2, 1, \"early game, uneven scores\"),\n",
    "(\"Forty-Thirty\", 3, 2, \"early game, uneven scores\"),\n",
    "(\"Advantage Player 1\", 4, 3, \"endgame, with uneven scores\"),\n",
    "# Add one test case of \"Advantage Player 2\"\n",
    "(\"Advantage Player 2\", 4, 5, \"endgame, with uneven scores\"),\n",
    "(\"Advantage Player 1\", 23, 22, \"endgame, with uneven scores\"),\n",
    "(\"Deuce\", 3, 3, \"endgame, with even scores\"),\n",
    "(\"Deuce\", 4, 4, \"endgame, with even scores\"),\n",
    "(\"Deuce\", 14, 14, \"endgame, with even scores\"),\n",
    "(\"Win for Player 1\", 4, 0, \"endgame, with winner\"),\n",
    "(\"Win for Player 2\", 1, 4, \"endgame, with winner\"),\n",
    "(\"Win for Player 1\", 6, 4, \"endgame, with winner\"),\n",
    "])\n",
    "@pytest.mark.parametrize(*examples)\n",
    "def test_tennis_scores(expected_score, player1_points, player2_points, comment):\n",
    "    assert expected_score == tennis_score(player1_points, player2_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ python -m pytest --cov-report term-missing --cov tennis\n",
    "========================================================= test session starts =========================================================\n",
    "platform linux -- Python 3.6.4, pytest-3.4.2, py-1.5.2, pluggy-0.6.0\n",
    "rootdir: /home/renwei/repos/github/learning-ml/python/pluralsight-unit-testing-with-python/coverage_example_pytest, inifile:\n",
    "plugins: cov-2.5.1\n",
    "collected 16 items                                                                                                                    \n",
    "\n",
    "test_tennis.py ................                                                                                                 [100%]\n",
    "\n",
    "----------- coverage: platform linux, python 3.6.4-final-0 -----------\n",
    "Name        Stmts   Miss  Cover   Missing\n",
    "-----------------------------------------\n",
    "tennis.py      32      0   100%\n",
    "\n",
    "\n",
    "====================================================== 16 passed in 0.07 seconds ======================================================\n",
    "```\n",
    "\n",
    "## 6.6 Measuring coverage of `unittest` tests\n",
    "\n",
    "(1) Two steps for generating the coverage report\n",
    "\n",
    "```bash\n",
    "$ python -m unittest\n",
    "...............\n",
    "----------------------------------------------------------------------\n",
    "Ran 15 tests in 0.001s\n",
    "\n",
    "OK\n",
    "$ python -m coverage run -m unittest\n",
    "...............\n",
    "----------------------------------------------------------------------\n",
    "Ran 15 tests in 0.001s\n",
    "\n",
    "OK\n",
    "```\n",
    "\n",
    "(2) To see the report in the terminal,\n",
    "\n",
    "```\n",
    "$ python -m coverage report\n",
    "Name             Stmts   Miss  Cover\n",
    "------------------------------------\n",
    "tennis.py           36      5    86%\n",
    "test_tennis.py      17      0   100%\n",
    "------------------------------------\n",
    "TOTAL               53      5    91%\n",
    "```\n",
    "\n",
    "You may also view the html report in a browser.\n",
    "\n",
    "```bash\n",
    "$ python -m coverage html\n",
    "```\n",
    "\n",
    "## 6.7 Use coverage data to add tests to legacy code\n",
    "\n",
    "Refactor an inventory system.\n",
    "\n",
    "Set the `branch` flag in a configuration file `.coveragerc` to also measure the branch coverage:\n",
    "\n",
    "```\n",
    "[run]\n",
    "branch = True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE AS gilded_rose.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "class GildedRose(object):\n",
    "\n",
    "    def __init__(self, items):\n",
    "        self.items = items\n",
    "\n",
    "    def update_quality(self):\n",
    "        for item in self.items:\n",
    "            if item.name != \"Aged Brie\" and item.name != \"Backstage passes to a TAFKAL80ETC concert\":\n",
    "                if item.quality > 0:\n",
    "                    if item.name != \"Sulfuras, Hand of Ragnaros\":\n",
    "                        item.quality = item.quality - 1\n",
    "            else:\n",
    "                if item.quality < 50:\n",
    "                    item.quality = item.quality + 1\n",
    "                    if item.name == \"Backstage passes to a TAFKAL80ETC concert\":\n",
    "                        if item.sell_in < 11:\n",
    "                            if item.quality < 50:\n",
    "                                item.quality = item.quality + 1\n",
    "                        if item.sell_in < 6:\n",
    "                            if item.quality < 50:\n",
    "                                item.quality = item.quality + 1\n",
    "            if item.name != \"Sulfuras, Hand of Ragnaros\":\n",
    "                item.sell_in = item.sell_in - 1\n",
    "            if item.sell_in < 0:\n",
    "                if item.name != \"Aged Brie\":\n",
    "                    if item.name != \"Backstage passes to a TAFKAL80ETC concert\":\n",
    "                        if item.quality > 0:\n",
    "                            if item.name != \"Sulfuras, Hand of Ragnaros\":\n",
    "                                item.quality = item.quality - 1\n",
    "                    else:\n",
    "                        item.quality = item.quality - item.quality\n",
    "                else:\n",
    "                    if item.quality < 50:\n",
    "                        item.quality = item.quality + 1\n",
    "\n",
    "    \n",
    "class Item:\n",
    "    def __init__(self, name, sell_in, quality):\n",
    "        self.name = name\n",
    "        self.sell_in = sell_in\n",
    "        self.quality = quality\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"%s, %s, %s\" % (self.name, self.sell_in, self.quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE AS test_gilded_rose.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import pytest\n",
    "\n",
    "from gilded_rose import Item, GildedRose\n",
    "\n",
    "examples = ((\"item_name\", \"initial_quality\", \"initial_sellin\", \"updated_quality\", \"updated_sellin\", \"comment\"),\n",
    "             ((\"foo\", 0, 0, 0, -1, \"typical item\"),\n",
    "             (\"foo\", 10, 0, 8, -1, \"typical item\"),\n",
    "             (\"Sulfuras, Hand of Ragnaros\", 0, 0, 0, 0, \"exceptional item\"),\n",
    "             (\"Sulfuras, Hand of Ragnaros\", 10, 0, 10, 0, \"exceptional item\"),\n",
    "             (\"Sulfuras, Hand of Ragnaros\", 10, -1, 10, -1, \"exceptional item\"),\n",
    "             (\"Aged Brie\", 0, 0, 2, -1, \"brie item\"),\n",
    "             (\"Backstage passes to a TAFKAL80ETC concert\", 0, 0, 0, -1, \"backstage pass item\")\n",
    "           ))\n",
    "@pytest.mark.parametrize(*examples)\n",
    "def test_update_quality(item_name, initial_quality, initial_sellin, updated_quality, updated_sellin, comment):\n",
    "    item = Item(item_name, initial_sellin, initial_quality)\n",
    "    gilded_rose = GildedRose([item])\n",
    "    gilded_rose.update_quality()\n",
    "    assert item.quality == updated_quality\n",
    "    assert item.sell_in == updated_sellin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ python -m pytest --cov-report term-missing --cov gilded_rose\n",
    "========================================================= test session starts =========================================================\n",
    "platform linux -- Python 3.6.4, pytest-3.4.2, py-1.5.2, pluggy-0.6.0\n",
    "rootdir: /home/renwei/repos/github/learning-ml/python/pluralsight-unit-testing-with-python/gilded_rose_example, inifile:\n",
    "plugins: cov-2.5.1\n",
    "collected 7 items                                                                                                                     \n",
    "\n",
    "test_gilded_rose.py .......                                                                                                     [100%]\n",
    "\n",
    "----------- coverage: platform linux, python 3.6.4-final-0 -----------\n",
    "Name             Stmts   Miss  Cover   Missing\n",
    "----------------------------------------------\n",
    "gilded_rose.py      36      1    97%   46\n",
    "\n",
    "\n",
    "====================================================== 7 passed in 0.05 seconds =======================================================\n",
    "$ python -m pytest --cov-report html --cov gilded_rose\n",
    "========================================================= test session starts =========================================================\n",
    "platform linux -- Python 3.6.4, pytest-3.4.2, py-1.5.2, pluggy-0.6.0\n",
    "rootdir: /home/renwei/repos/github/learning-ml/python/pluralsight-unit-testing-with-python/gilded_rose_example, inifile:\n",
    "plugins: cov-2.5.1\n",
    "collected 7 items                                                                                                                     \n",
    "\n",
    "test_gilded_rose.py .......                                                                                                     [100%]\n",
    "\n",
    "----------- coverage: platform linux, python 3.6.4-final-0 -----------\n",
    "Coverage HTML written to dir htmlcov\n",
    "\n",
    "\n",
    "====================================================== 7 passed in 0.05 seconds =======================================================\n",
    "```\n",
    "\n",
    "## 6.8 Good and bad uses for coverage metrics\n",
    "\n",
    "### 6.8.1 Interpreting coverage data\n",
    "\n",
    "(1) Find missing test cases\n",
    "\n",
    "(2) Get legacy code under test\n",
    "\n",
    "(3) Continuous integration - constant measurement\n",
    "\n",
    "### 6.8.2 Coverage metric to aim for?\n",
    "\n",
    "It depends.\n",
    "\n",
    "### 6.8.3 Test quality != Coverage\n",
    "\n",
    "100% test coverage != no bugs\n",
    "\n",
    "Besides code coverage,\n",
    "\n",
    "(1) Code review\n",
    "\n",
    "(2) Bug reports\n",
    "\n",
    "(3) Confidence to refactor\n",
    "\n",
    "(4) Flickering tests\n",
    "\n",
    "## 6.9 Module review\n",
    "\n",
    "(1) Parameterized test with `unittest` and `pytest`\n",
    "\n",
    "(2) Measuring coverage of tests\n",
    "\n",
    "* to find missing test cases\n",
    "* to improve regression protection\n",
    "\n",
    "(3) Interpreting coverage data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
